{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import img_as_uint\n",
    "from skimage.transform import resize\n",
    "from skimage.util import invert\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage import data\n",
    "from skimage import morphology\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Misc Functions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = [(-1, -1), (-1, 0), (-1, 1), (0, 1), (1, 1), (1, 0), (1, -1), (0, -1), (-1, -1)]\n",
    "\n",
    "def minutiae_at(pixels, i, j):\n",
    "    values = [pixels[i + k][j + l] for k, l in cells]\n",
    "\n",
    "    crossings = 0\n",
    "    for k in range(0, 8):\n",
    "        crossings += abs(values[k] - values[k + 1])\n",
    "    crossings /= 2\n",
    "\n",
    "    if pixels[i][j] == 0:\n",
    "        if crossings == 1:\n",
    "            return \"ending\"\n",
    "        if crossings == 3:\n",
    "            return \"bifurcation\"\n",
    "    return \"none\"\n",
    "\n",
    "def load_image(im):\n",
    "    (x, y) = im.size\n",
    "    im_load = im.load()\n",
    "\n",
    "    result = []\n",
    "    for i in range(0, x):\n",
    "        result.append([])\n",
    "        for j in range(0, y):\n",
    "            result[i].append(im_load[i, j])\n",
    "\n",
    "    return result\n",
    "\n",
    "def apply_to_each_pixel(pixels, f):\n",
    "    for i in range(0, len(pixels)):\n",
    "        for j in range(0, len(pixels[i])):\n",
    "            pixels[i][j] = f(pixels[i][j])\n",
    "            \n",
    "def detect_minutiaes(img_path):\n",
    "    im = Image.open(img_path)\n",
    "    pixels = load_image(im)\n",
    "    apply_to_each_pixel(pixels, lambda x: 0.0 if x > 10 else 1.0)\n",
    "\n",
    "    (x, y) = im.size\n",
    "    result = im.convert(\"RGB\")\n",
    "\n",
    "    draw = ImageDraw.Draw(result)\n",
    "\n",
    "    colors = {\"ending\" : (0, 255, 0), \"bifurcation\" : (255, 0, 0)}\n",
    "\n",
    "    ellipse_size = 1\n",
    "    \n",
    "    for i in range(1, x - 1):\n",
    "        for j in range(1, y - 1):\n",
    "            minutiae = minutiae_at(pixels, i, j)\n",
    "            if minutiae != \"none\":\n",
    "                draw.ellipse([(i - ellipse_size, j - ellipse_size), (i + ellipse_size, j + ellipse_size)], outline = colors[minutiae])\n",
    "    del draw\n",
    "\n",
    "    return result\n",
    "\n",
    "def saveModel(model):\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "def loadModel():\n",
    "    # load json and create model\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "  \n",
    "    return loaded_model\n",
    "\n",
    "def performThinning(img_path):\n",
    "    inp_image = imread(img_path)\n",
    "\n",
    "    img_gray = rgb2gray(inp_image)\n",
    "\n",
    "    img_gray=invert(img_gray)\n",
    "\n",
    "    img_resized = resize(img_gray, (103, 96),anti_aliasing=True)\n",
    "\n",
    "    thresh = threshold_otsu(img_resized)\n",
    "    binary_thresh_img = img_resized > thresh\n",
    "\n",
    "    #binary_thresh_img=binary_thresh_img.transpose(2,0,1).reshape(103,-1)\n",
    "\n",
    "    skeleton = skeletonize(binary_thresh_img)\n",
    "    \n",
    "    return (skeleton,inp_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Image Preprocessing (Binarizing,Thinning)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100__M_Left_index_finger.BMP\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-946e4cb9ea71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mskeleton\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperformThinning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;31m#out_thin = morphology.thin(binary_thresh_img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-183-b37dfedb3325>\u001b[0m in \u001b[0;36mperformThinning\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mbinary_thresh_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_resized\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mbinary_thresh_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary_thresh_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m103\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mskeleton\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskeletonize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_thresh_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(\"fingerprint_dataset\"):\n",
    "    #char_list.append(os.path.basename(root).split('_')[-1])\n",
    "    for f in files:\n",
    "        print(f)\n",
    "        skeleton = performThinning(os.path.join(root,f))[0]\n",
    "        #out_thin = morphology.thin(binary_thresh_img)\n",
    "\n",
    "        imsave(\"processed_fingerprint/\"+f.split('.')[0]+\".png\", img_as_uint(skeleton))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Generating Class list to be Predicted</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M_Left_index_finger', 'M_Left_little_finger', 'M_Left_middle_finger', 'M_Left_ring_finger', 'M_Left_thumb_finger', 'M_Right_index_finger', 'M_Right_little_finger', 'M_Right_middle_finger', 'M_Right_ring_finger', 'M_Right_thumb_finger', 'F_Left_index_finger', 'F_Left_little_finger', 'F_Left_middle_finger', 'F_Left_ring_finger', 'F_Left_thumb_finger', 'F_Right_index_finger', 'F_Right_little_finger', 'F_Right_middle_finger', 'F_Right_ring_finger', 'F_Right_thumb_finger']\n"
     ]
    }
   ],
   "source": [
    "ext_list=[]\n",
    "for root, dirs, files in os.walk(\"processed_fingerprint\"):\n",
    "    #char_list.append(os.path.basename(root).split('_')[-1])\n",
    "    for f in files:\n",
    "        part=f.split(\"__\")\n",
    "        if part[1].split(\".\")[0] not in ext_list:\n",
    "            ext_list.append(part[1].split(\".\")[0])\n",
    "print(ext_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extracting Minutiae Points and Generating Dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['pixel_'+str(i) for i in range(0,96*103)])\n",
    "df['category']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0\n",
    "for root, dirs, files in os.walk(\"processed_fingerprint\"):\n",
    "    #char_list.append(os.path.basename(root).split('_')[-1])\n",
    "    for f in files:\n",
    "        print(f)\n",
    "        im = Image.open(os.path.join(root,f))\n",
    "        pixels = load_image(im)\n",
    "        apply_to_each_pixel(pixels, lambda x: 0.0 if x > 10 else 1.0)\n",
    "\n",
    "        (x, y) = im.size\n",
    "        \n",
    "        points = np.zeros((x,y),dtype=int)\n",
    "        for i in range(1, x - 1):\n",
    "            for j in range(1, y - 1):\n",
    "                minutiae = minutiae_at(pixels, i, j)\n",
    "                if minutiae != \"none\":\n",
    "                    if minutiae == \"ending\":\n",
    "                        points[i,j] = 1\n",
    "                    if minutiae == \"bifurcation\":\n",
    "                        points[i,j] = 2\n",
    "                        \n",
    "        pixel=list(points.flatten())\n",
    "        pixel.append(f)\n",
    "        df.loc[index]=pixel\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Normalizing Category Column</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,v in enumerate(df['category']):\n",
    "    ext = v.split('__')[-1].split('.')[0]\n",
    "    print(ext)\n",
    "    if ext in ext_list:\n",
    "        print(ext_list.index(ext))\n",
    "        df['category'].iloc[i]=ext_list.index(ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 9889)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Splitting into Train and Test Set in 4:1 ratio</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=df.iloc[:,:] \n",
    "y=X['category']\n",
    "X.drop([\"category\"], inplace = True, axis = 1)\n",
    "#y=np.array(df.iloc[:,-1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 96, 103 , 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 96, 103 , 1).astype('float32')\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train).astype('int32')\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Building 2D CNN using Keras</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(40, kernel_size=5, padding=\"same\",input_shape=(96, 103, 1), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(70, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "model.add(Conv2D(500, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(1024, kernel_size=3, padding=\"valid\", activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'  ))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=100, activation='relu'  ))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=100, activation='relu'  ))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(20))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 96, 103, 40)       1040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 48, 51, 40)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 48, 51, 70)        25270     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 48, 51, 500)       315500    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 24, 25, 500)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 22, 23, 1024)      4609024   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 11, 11, 1024)      0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 123904)            0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               12390500  \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 17,363,554\n",
      "Trainable params: 17,363,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training Neural Network</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800 samples, validate on 1200 samples\n",
      "Epoch 1/10\n",
      "4800/4800 [==============================] - 1463s 305ms/step - loss: 1.7436 - acc: 0.4290 - val_loss: 1.9348 - val_acc: 0.3958\n",
      "Epoch 2/10\n",
      "4800/4800 [==============================] - 1448s 302ms/step - loss: 1.5956 - acc: 0.4783 - val_loss: 1.9410 - val_acc: 0.3850\n",
      "Epoch 3/10\n",
      "4800/4800 [==============================] - 1458s 304ms/step - loss: 1.4771 - acc: 0.5065 - val_loss: 2.0205 - val_acc: 0.3817\n",
      "Epoch 4/10\n",
      "4800/4800 [==============================] - 1369s 285ms/step - loss: 1.3409 - acc: 0.5538 - val_loss: 2.1353 - val_acc: 0.3908\n",
      "Epoch 5/10\n",
      "4800/4800 [==============================] - 1107s 231ms/step - loss: 1.2150 - acc: 0.5863 - val_loss: 2.2730 - val_acc: 0.3667\n",
      "Epoch 6/10\n",
      "4800/4800 [==============================] - 1103s 230ms/step - loss: 1.0548 - acc: 0.6410 - val_loss: 2.4280 - val_acc: 0.3708\n",
      "Epoch 7/10\n",
      "4800/4800 [==============================] - 1020s 212ms/step - loss: 0.9303 - acc: 0.6838 - val_loss: 2.5415 - val_acc: 0.3725\n",
      "Epoch 8/10\n",
      "4800/4800 [==============================] - 1019s 212ms/step - loss: 0.8689 - acc: 0.6888 - val_loss: 2.7462 - val_acc: 0.3467\n",
      "Epoch 9/10\n",
      "4800/4800 [==============================] - 1013s 211ms/step - loss: 0.7715 - acc: 0.7350 - val_loss: 2.8813 - val_acc: 0.3692\n",
      "Epoch 10/10\n",
      "4800/4800 [==============================] - 1014s 211ms/step - loss: 0.6858 - acc: 0.7606 - val_loss: 3.0870 - val_acc: 0.3542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2203ffbbe48>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "              batch_size=50,\n",
    "              epochs=10,\n",
    "              validation_data=(X_test, y_test),\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.086960916519165, 0.3541666666666667]\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose = 10 )\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "saveModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alexk\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\alexk\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "loaded_model=loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extracting Feature and Testing Input Fingerprint</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"13__F_Left_ring_finger.png\"\n",
    "\n",
    "skeleton,inp_image = performThinning(img_path)\n",
    "\n",
    "imsave(\"test.png\", img_as_uint(skeleton))\n",
    "\n",
    "tdf = pd.DataFrame(columns=['pixel_'+str(i) for i in range(0,96*103)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"test.png\")\n",
    "pixels = load_image(im)\n",
    "apply_to_each_pixel(pixels, lambda x: 0.0 if x > 10 else 1.0)\n",
    "\n",
    "(x, y) = im.size\n",
    "\n",
    "points = np.zeros((x,y),dtype=int)\n",
    "for i in range(1, x - 1):\n",
    "    for j in range(1, y - 1):\n",
    "        minutiae = minutiae_at(pixels, i, j)\n",
    "        if minutiae != \"none\":\n",
    "            if minutiae == \"ending\":\n",
    "                points[i,j] = 1\n",
    "            if minutiae == \"bifurcation\":\n",
    "                points[i,j] = 2\n",
    "\n",
    "pixel=list(points.flatten())\n",
    "tdf.loc[0]=pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4d8dfc743853>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0max0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0max0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0max0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "f, (ax0, ax1, ax2, ax3) = plt.subplots(1, 4, figsize=(10, 3))\n",
    "\n",
    "ax0.imshow(inp_image, cmap='gray')\n",
    "ax0.set_title('Input')\n",
    "\n",
    "ax1.imshow(skeleton, cmap='gray')\n",
    "ax1.set_title('Skeletonize')\n",
    "\n",
    "out_thin = morphology.thin(skeleton)\n",
    "ax2.imshow(out_thin, cmap='gray')\n",
    "ax2.set_title('Thin')\n",
    "\n",
    "minu = detect_minutiaes(\"test.png\")\n",
    "ax3.imshow(minu, cmap='gray')\n",
    "ax3.set_title('Minutiae Detect')\n",
    "\n",
    "#plt.savefig('smaple.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Predicting Class</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F_Left_ring_finger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId            Category\n",
       "0        1  F_Left_ring_finger"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array(tdf.iloc[:,:])\n",
    "\n",
    "test= test.reshape(1,96, 103 , 1).astype('float32')\n",
    "\n",
    "res = loaded_model.predict(test)\n",
    "res = np.argmax(res,axis = 1)\n",
    "res = pd.Series(ext_list[res[0]], name=\"Category\")\n",
    "submission = pd.concat([pd.Series(range(1 ,2) ,name = \"ImageId\"),   res],axis = 1)\n",
    "#submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)\n",
    "submission.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
